I am a machine learning researcher working at the intersection of Reinforcement Learning and Foundation Models. In particular I am interested in using semi-supervised learning on offline datasets to improve in-context learning in multi-task settings. Until recently, the dominant trend in machine learning has been a move away from priors and inductive biases toward general methods that make minimal assumptions about the problem domain. The cost of this approach has been a massive increase in the quantity of data required for learning.  Recent innovations in meta-learning have demonstrated some success at addressing this issue, but many of these methods have not been shown to scale. Past attempts to encode priors into models failed because they were hand-coded and therefore parasitic on the mind of the engineer. Today, using foundation models, we can effectively learn "priors" from empirical data. A method that works in any world will be slow. A method that only works in this world will be fast!
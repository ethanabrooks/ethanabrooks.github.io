
<!-- This document was automatically generated with bibtex2html 1.99
     (see http://www.lri.fr/~filliatr/bibtex2html/),
     with the following command:
     bibtex2html -nodoc -q papers.bib  -->


<table>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="pmlr-v139-brooks21a">1</a>]
</td>
<td class="bibtexitem">
<b>Brooks, Ethan</b>, Janarthanan Rajendran, Richard&nbsp;L Lewis, and Satinder
  Singh.
 Reinforcement learning of implicit and explicit control flow
  instructions.
 In Marina Meila and Tong Zhang, editors, <em>Proceedings of the 38th
  International Conference on Machine Learning</em>, volume 139 of <em>Proceedings
  of Machine Learning Research</em>, pages 1082--1091. PMLR, 18--24 Jul 2021.
[&nbsp;<a href="papers_bib.html#pmlr-v139-brooks21a">bib</a>&nbsp;| 
<a href="https://proceedings.mlr.press/v139/brooks21a.html">.html</a>&nbsp;| 
<a href="http://proceedings.mlr.press/v139/brooks21a/brooks21a.pdf">.pdf</a>&nbsp;]
<blockquote><font size="-1">
Learning to flexibly follow task instructions in dynamic environments poses interesting challenges for reinforcement learning agents. We focus here on the problem of learning control flow that deviates from a strict step-by-step execution of instructions—that is, control flow that may skip forward over parts of the instructions or return backward to previously completed or skipped steps. Demand for such flexible control arises in two fundamental ways: explicitly when control is specified in the instructions themselves (such as conditional branching and looping) and implicitly when stochastic environment dynamics require re-completion of instructions whose effects have been perturbed, or opportunistic skipping of instructions whose effects are already present. We formulate an attention-based architecture that meets these challenges by learning, from task reward only, to flexibly attend to and condition behavior on an internal encoding of the instructions. We test the architecture’s ability to learn both explicit and implicit control in two illustrative domains—one inspired by Minecraft and the other by StarCraft—and show that the architecture exhibits zero-shot generalization to novel instructions of length greater than those in a training set, at a performance level unmatched by three baseline recurrent architectures and one ablation architecture.
</font></blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="1stlt2014hazing">2</a>]
</td>
<td class="bibtexitem">
Ethan Brooks.
 Hazing versus challenging.
 <em>Marine Corps Gazette</em>, 98(8):24--25, 2014.
[&nbsp;<a href="papers_bib.html#1stlt2014hazing">bib</a>&nbsp;]

</td>
</tr>
</table><hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.99.</em></p>
